---
title: 'Mediapipe to BioVision Hierarchy (BVH) Converter'
tags:
  - JavaScript
  - three.js
  - mediapipe
  - pose
  - hand tracking
  - 3D
  - animation
authors:
  - name: 'Tejaswi Gowda'
    orcid: 0000-0002-0896-6526
    equal-contrib: true
    affiliation: "1"
   
affiliations:
 - name: "Arizona State University, Tempe, AZ, USA"
   index: 1
date: 22 February 2024
bibliography: paper.bib

# Optional fields if submitting to a AAS journal too, see this blog post:
# https://blog.joss.theoj.org/2018/12/a-new-collaboration-with-aas-publishing
aas-doi: 10.3847/xxxxx <- update this with the DOI from AAS once you know it.
aas-journal: Astrophysical Journal <- The name of the AAS journal.
---

# Summary

This is a simple tool to convert the output of the MediaPipe Pose model to a BVH file. The BVH file can be used to animate a 3D character in Blender or any other 3D software that supports the BVH format. It also generates blendshapes for the face. The blendshapes can be used to animate a 3D character's face in Blender or any other 3D software that supports blendshapes.

# Statement of need

The MediaPipe Pose model outputs the 3D coordinates of 33 keypoints on the human body. The keypoints include the 25 keypoints of the body, 21 keypoints of the left hand, 21 keypoints of the right hand, and 468 keypoints of the face. The 3D coordinates of these keypoints can be used to animate a 3D character in Blender or any other 3D software that supports the BVH format. The 3D coordinates of the face keypoints can be used to generate blendshapes for the face. The blendshapes can be used to animate a 3D character's face in Blender or any other 3D software that supports blendshapes.

# Key Features

1. Converts the output of the MediaPipe Pose model to a BVH file.
![Caption for example figure.](figure.png){ width=20% }


2. Generates blendshapes for the face.
![Caption for example figure.](figure.png){ width=20% }

3. Hand tracking.
![Caption for example figure.](figure.png){ width=20% }


4. Plug and play into any 3D software that supports BVH and blendshapes.
5. No installation required. Just open the HTML file in the browser.

# Installation

This software is released under the GNU General Public License version 3 (GPLv3). The complete license is provided as LICENSE.txt

# Dependencies

A modern web browser that supports the WebAssembly. Tested on Chrome and Firefox. For development, you will need Node.js and http-server.

# Usage

```bash
git clone https://github.com/tejaswigowda/mediapipe-pose2bvh.git
cd mediapipe-pose2bvh
http-server
```

Open the browser and go to `http://localhost:8080/`. To record use 
![Start Record](./start.png).

To stop recording use
![Stop Record](./stop.png).

The BVH file and the blendshapes will be generated and downloaded.



# Architecture

The software is written in JavaScript and uses the three.js library for 3D rendering. The software uses the MediaPipe Pose model to get the 3D coordinates of the keypoints. The 3D coordinates are then used to generate the BVH file and the blendshapes. The BVH file and the blendshapes are then downloaded.

![Data flow](./docs/imgs/arch.png){ width=100% }



# Demo

[![Demo](./demo.gif)](https://tejaswigowda.github.io/mediapipe-pose2bvh/)

Go to [https://tejaswigowda.github.io/mediapipe-pose2bvh/](https://tejaswigowda.github.io/mediapipe-pose2bvh/) and enable the camera. The 3D character will start animating based on your body movements. The 3D character's face will also animate based on your facial expressions.

# Applications

## Animation

The BVH file generated by the software can be used to animate a 3D character in Blender or any other 3D software that supports the BVH format.

## Facial Animation

The blendshapes generated by the software can be used to animate a 3D character's face in Blender or any other 3D software that supports blendshapes.

## Kinematic Analysis

Full bone movement can be used to analyze the kinematics of the human body.

## Extended Reality

Full body, finger and face tracking can be used to animate a 3D character in virtual reality. This will allow the user to interact with the 3D character in real-time.

## Gaming

Body pose generated can be used to animate a 3D character in a game. This will allow the user to control the 3D character using their body movements. The data generated works well with the Unity game engine.

## Telemedicine

The 3D bone movement generated can be used to analyze the movements of the human body. This can be used to diagnose and treat musculoskeletal disorders.

## Sports

The 3D bone movement generated can be used to analyze the movements of the human body. This can be used to analyze the movements of athletes and improve their performance.

## Security

The 3D bone movement generated can be used to analyze the movements of the human body. This can be used to detect and prevent crimes.

## Robotics

The 3D bone movement generated can be used to analyze the movements of the human body. This can be used to control robots using body movements.

# Limitations and Future Work

The software currently supports only the MediaPipe Pose model. In the future, support for other pose estimation models will be added. The software currently supports only the BVH format. In the future, support for other animation formats will be added. The software currently supports only the blendshapes for the face. In the future, support for blendshapes for the body will be added. The software currently estimates distance from the camera. In the future, support for estimating distance using the iris model will be added. Fusing multiple camera feeds to estimate 3D coordinates of the keypoints will be added. Smoothing the 3D coordinates of the keypoints will be added.

The software currently estimates distance from the camera. In the future, support for estimating distance using the iris model will be added[1].

Fusing multiple camera feeds to estimate 3D coordinates of the keypoints will be added[2].



# Acknowledgements


# Citations

Citations to entries in paper.bib should be in
[rMarkdown](http://rmarkdown.rstudio.com/authoring_bibliographies_and_citations.html)
format.

If you want to cite a software repository URL (e.g. something on GitHub without a preferred
citation) then you can do it with the example BibTeX entry below for @fidgit.

For a quick reference, the following citation commands can be used:
- `@author:2001`  ->  "Author et al. (2001)"
- `[@author:2001]` -> "(Author et al., 2001)"
- `[@author1:2001; @author2:2001]` -> "(Author1 et al., 2001; Author2 et al., 2002)"

# Figures

Figures can be included like this:
![Caption for example figure.\label{fig:example}](figure.png)
and referenced from text using \autoref{fig:example}.

Figure sizes can be customized by adding an optional second parameter:
![Caption for example figure.](figure.png){ width=20% }

# Acknowledgements

We acknowledge contributions from Brigitta Sipocz, Syrtis Major, and Semyeong
Oh, and support from Kathryn Johnston during the genesis of this project.

# References

Example paper.bib file:

@article{Pearson:2017,
  	url = {http://adsabs.harvard.edu/abs/2017arXiv170304627P},
  	Archiveprefix = {arXiv},
  	Author = {{Pearson}, S. and {Price-Whelan}, A.~M. and {Johnston}, K.~V.},
  	Eprint = {1703.04627},
  	Journal = {ArXiv e-prints},
  	Keywords = {Astrophysics - Astrophysics of Galaxies},
  	Month = mar,
  	Title = {{Gaps in Globular Cluster Streams: Pal 5 and the Galactic Bar}},
  	Year = 2017
}

@book{Binney:2008,
  	url = {http://adsabs.harvard.edu/abs/2008gady.book.....B},
  	Author = {{Binney}, J. and {Tremaine}, S.},
  	Booktitle = {Galactic Dynamics: Second Edition, by James Binney and Scott Tremaine.~ISBN 978-0-691-13026-2 (HB).~Published by Princeton University Press, Princeton, NJ USA, 2008.},
  	Publisher = {Princeton University Press},
  	Title = {{Galactic Dynamics: Second Edition}},
  	Year = 2008
}

@article{gaia,
    author = {{Gaia Collaboration}},
    title = "{The Gaia mission}",
    journal = {Astronomy and Astrophysics},
    archivePrefix = "arXiv",
    eprint = {1609.04153},
    primaryClass = "astro-ph.IM",
    keywords = {space vehicles: instruments, Galaxy: structure, astrometry, parallaxes, proper motions, telescopes},
    year = 2016,
    month = nov,
    volume = 595,
    doi = {10.1051/0004-6361/201629272},
    url = {http://adsabs.harvard.edu/abs/2016A%26A...595A...1G},
}

@article{astropy,
    author = {{Astropy Collaboration}},
    title = "{Astropy: A community Python package for astronomy}",
    journal = {Astronomy and Astrophysics},
    archivePrefix = "arXiv",
    eprint = {1307.6212},
    primaryClass = "astro-ph.IM",
    keywords = {methods: data analysis, methods: miscellaneous, virtual observatory tools},
    year = 2013,
    month = oct,
    volume = 558,
    doi = {10.1051/0004-6361/201322068},
    url = {http://adsabs.harvard.edu/abs/2013A%26A...558A..33A}
}

@misc{fidgit,
  author = {A. M. Smith and K. Thaney and M. Hahnel},
  title = {Fidgit: An ungodly union of GitHub and Figshare},
  year = {2020},
  publisher = {GitHub},
  journal = {GitHub repository},
  url = {https://github.com/arfon/fidgit}
}

